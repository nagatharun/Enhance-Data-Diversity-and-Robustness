# -*- coding: utf-8 -*-
"""CycleGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tmgd6rmA3wUc8Rt4LY8A89itFL50g1DE
"""

!pip install torch torchvision

from google.colab import drive
drive.mount('/content/drive')

train_folder = "/content/drive/MyDrive/AI-Capstone/Datasets/simple-dataset/"

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# Transform to resize images and normalize to [-1, 1] range (common for GANs)
transform = transforms.Compose([
    transforms.Resize((256, 256)),  # Resize to 256x256 pixels
    transforms.ToTensor(),          # Convert image to tensor
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]
])

# Load the laparoscopic images
dataset = datasets.ImageFolder(root=train_folder, transform=transform)

# DataLoader for batching the dataset
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

import torch.nn as nn

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.model = nn.Sequential(
            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),  # Latent vector -> image
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),
            nn.Tanh()  # Output image with values in [-1, 1]
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()

        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
        )

        # Add a dummy forward pass to calculate the size after the convolution layers
        self._to_linear = None
        self._calculate_flattened_size()

        self.fc = nn.Linear(self._to_linear, 1)  # The output is a scalar per image

    def _calculate_flattened_size(self):
        # Create a dummy tensor of the same size as the input image
        x = torch.zeros(1, 3, 128, 128)  # Adjust if using a different image size
        x = self.conv_layers(x)
        self._to_linear = x.numel()

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(-1, self._to_linear)
        return self.fc(x)

import torch.optim as optim

# Create models
generator = Generator().to(device)
discriminator = Discriminator().to(device)

# Loss function (Binary Cross-Entropy)
criterion = nn.BCELoss()

# Optimizers
lr = 0.0002
beta1 = 0.5
G_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))
D_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))

import torch

num_epochs = 100  # Number of epochs
for epoch in range(num_epochs):
    for i, data in enumerate(dataloader):
        real_images = data[0].to(device)

        # Dynamically get the batch size from the real images
        batch_size = real_images.size(0)

        # Create labels with the same batch size for real images
        real_labels = torch.ones(batch_size, 1).to(device)  # Label all real images as 1

        # Train Discriminator
        D_optimizer.zero_grad()

        # Train with real images
        D_real_output = discriminator(real_images)
        D_real_output = D_real_output.view(batch_size, -1)  # Flatten the output if necessary
        D_real_loss = criterion(D_real_output, real_labels)  # Loss for real images

        # Train with fake images generated by the Generator
        noise = torch.randn(batch_size, 100, 1, 1).to(device)  # Noise for generator input
        fake_images = generator(noise)
        fake_labels = torch.zeros(batch_size, 1).to(device)  # Label all fake images as 0

        D_fake_output = discriminator(fake_images.detach())  # Detach to avoid backprop through Generator
        D_fake_output = D_fake_output.view(batch_size, -1)  # Flatten the output to match fake_labels
        D_fake_loss = criterion(D_fake_output, fake_labels)  # Loss for fake images

        # Total Discriminator Loss
        D_loss = D_real_loss + D_fake_loss
        D_loss.backward()
        D_optimizer.step()

        # Train Generator
        G_optimizer.zero_grad()

        # Generator loss: want to fool the Discriminator
        G_labels = torch.ones(batch_size, 1).to(device)  # Fake images should be classified as real
        G_output = discriminator(fake_images)
        G_output = G_output.view(batch_size, -1)  # Flatten the output to match the size of G_labels
        G_loss = criterion(G_output, G_labels)  # Loss for the Generator

        G_loss.backward()
        G_optimizer.step()

        # Print out losses every 50 steps
        if i % 50 == 0:
            print(f"Epoch [{epoch}/{num_epochs}], Step [{i}/{len(dataloader)}], D Loss: {D_loss.item()}, G Loss: {G_loss.item()}")

    # Save synthetic images at the end of each epoch
    if epoch % 10 == 0:
        fake_images = fake_images.detach().cpu()
        # Save or visualize generated images (you can use a function like save_generated_images)
        save_generated_images(fake_images, epoch)

